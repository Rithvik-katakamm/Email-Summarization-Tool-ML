{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Email Summerizer using Neural Networks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementaton "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Results:\n",
      "{'random_forest': {'mean_cv_score': 36.1281, 'std_cv_score': 22.375644866029372}, 'gradient_boosting': {'mean_cv_score': 60.524527966360154, 'std_cv_score': 18.53555830456647}, 'ridge_regression': {'mean_cv_score': 26.703309075302855, 'std_cv_score': 17.689221212787427}}\n",
      "\n",
      "\n",
      "Ablation Study Results:\n",
      "Config: {'feature_dim': 50}, Results: {'random_forest': {'mean_cv_score': 36.1281, 'std_cv_score': 22.375644866029372}, 'gradient_boosting': {'mean_cv_score': 60.524527966360154, 'std_cv_score': 18.53555830456647}, 'ridge_regression': {'mean_cv_score': 26.703309075302844, 'std_cv_score': 17.689221212787423}}\n",
      "Config: {'feature_dim': 100}, Results: {'random_forest': {'mean_cv_score': 36.1281, 'std_cv_score': 22.375644866029372}, 'gradient_boosting': {'mean_cv_score': 60.524527966360154, 'std_cv_score': 18.53555830456647}, 'ridge_regression': {'mean_cv_score': 26.703309075302865, 'std_cv_score': 17.689221212787444}}\n",
      "Config: {'feature_dim': 150}, Results: {'random_forest': {'mean_cv_score': 36.1281, 'std_cv_score': 22.375644866029372}, 'gradient_boosting': {'mean_cv_score': 60.524527966360154, 'std_cv_score': 18.53555830456647}, 'ridge_regression': {'mean_cv_score': 26.703309075302855, 'std_cv_score': 17.689221212787427}}\n",
      "Config: {'feature_dim': 200}, Results: {'random_forest': {'mean_cv_score': 36.1281, 'std_cv_score': 22.375644866029372}, 'gradient_boosting': {'mean_cv_score': 60.524527966360154, 'std_cv_score': 18.53555830456647}, 'ridge_regression': {'mean_cv_score': 26.703309075302833, 'std_cv_score': 17.689221212787444}}\n",
      "Config: {'regularization_strength': 0.01}, Results: {'random_forest': {'mean_cv_score': 36.1281, 'std_cv_score': 22.375644866029372}, 'gradient_boosting': {'mean_cv_score': 60.524527966360154, 'std_cv_score': 18.53555830456647}, 'ridge_regression': {'mean_cv_score': 26.734067738206846, 'std_cv_score': 17.678554088067056}}\n",
      "Config: {'regularization_strength': 0.1}, Results: {'random_forest': {'mean_cv_score': 36.1281, 'std_cv_score': 22.375644866029372}, 'gradient_boosting': {'mean_cv_score': 60.524527966360154, 'std_cv_score': 18.53555830456647}, 'ridge_regression': {'mean_cv_score': 26.731191978015566, 'std_cv_score': 17.679566310891108}}\n",
      "Config: {'regularization_strength': 1.0}, Results: {'random_forest': {'mean_cv_score': 36.1281, 'std_cv_score': 22.375644866029372}, 'gradient_boosting': {'mean_cv_score': 60.524527966360154, 'std_cv_score': 18.53555830456647}, 'ridge_regression': {'mean_cv_score': 26.703309075302876, 'std_cv_score': 17.68922121278743}}\n",
      "Config: {'regularization_strength': 10.0}, Results: {'random_forest': {'mean_cv_score': 36.1281, 'std_cv_score': 22.375644866029372}, 'gradient_boosting': {'mean_cv_score': 60.524527966360154, 'std_cv_score': 18.53555830456647}, 'ridge_regression': {'mean_cv_score': 26.493915790653723, 'std_cv_score': 17.755046691979803}}\n",
      "Config: {'tfidf_max_features': 3000}, Results: {'random_forest': {'mean_cv_score': 36.1281, 'std_cv_score': 22.375644866029372}, 'gradient_boosting': {'mean_cv_score': 60.524527966360154, 'std_cv_score': 18.53555830456647}, 'ridge_regression': {'mean_cv_score': 26.493915790653723, 'std_cv_score': 17.755046691979803}}\n",
      "Config: {'tfidf_max_features': 7000}, Results: {'random_forest': {'mean_cv_score': 36.1281, 'std_cv_score': 22.375644866029372}, 'gradient_boosting': {'mean_cv_score': 60.524527966360154, 'std_cv_score': 18.53555830456647}, 'ridge_regression': {'mean_cv_score': 26.493915790653734, 'std_cv_score': 17.755046691979796}}\n",
      "\n",
      "\n",
      "Bias-Variance Decomposition Results:\n",
      "{'random_forest': {'train_error': 4.514566666666666, 'validation_error': 19.968366666666665, 'difference': 15.453799999999998}, 'gradient_boosting': {'train_error': 6.837576495795447e-08, 'validation_error': 39.89899051359101, 'difference': 39.89899044521525}, 'ridge_regression': {'train_error': 0.08112923803903027, 'validation_error': 9.726682973245799, 'difference': 9.645553735206768}}\n",
      "\n",
      "\n",
      "Results visualization saved to 'results_visualization.png'.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, \n",
    "    cross_val_score, \n",
    "    KFold, \n",
    ")\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler, \n",
    "    LabelEncoder\n",
    ")\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, \n",
    "    mean_squared_error, \n",
    "    r2_score\n",
    ")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "class EmailSummarizationModel:\n",
    "    def __init__(self, config=None):\n",
    "        \"\"\"\n",
    "        Initialize the email summarization model with comprehensive configurations\n",
    "        \n",
    "        Args:\n",
    "            config (dict): Configuration parameters for model initialization\n",
    "        \"\"\"\n",
    "        self.config = config or {\n",
    "            'model_type': 'hybrid',\n",
    "            'feature_dim': 100,\n",
    "            'regularization_strength': 1.0,\n",
    "            'learning_rate': 0.001\n",
    "        }\n",
    "        \n",
    "        # Pre-processing components\n",
    "        self.scaler = StandardScaler()\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.tfidf_vectorizer = TfidfVectorizer(\n",
    "            max_features=5000, \n",
    "            stop_words='english'\n",
    "        )\n",
    "        self.dimensionality_reducer = TruncatedSVD(\n",
    "            n_components=self.config['feature_dim']\n",
    "        )\n",
    "        \n",
    "        # Model components\n",
    "        self.models = {\n",
    "            'random_forest': RandomForestRegressor(\n",
    "                n_estimators=100, \n",
    "                random_state=42\n",
    "            ),\n",
    "            'gradient_boosting': GradientBoostingRegressor(\n",
    "                n_estimators=100, \n",
    "                random_state=42\n",
    "            ),\n",
    "            'ridge_regression': Ridge(\n",
    "                alpha=self.config['regularization_strength']\n",
    "            )\n",
    "        }\n",
    "        \n",
    "        # Advanced pre-trained transformer\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
    "        self.transformer_model = AutoModelForSeq2SeqLM.from_pretrained('facebook/bart-large-cnn')\n",
    "        \n",
    "    def preprocess_data(self, emails, labels=None):\n",
    "        \"\"\"\n",
    "        Comprehensive data preprocessing pipeline\n",
    "        \n",
    "        Args:\n",
    "            emails (list): Raw email texts\n",
    "            labels (list, optional): Corresponding summary labels\n",
    "        \n",
    "        Returns:\n",
    "            tuple: Processed features and optional labels\n",
    "        \"\"\"\n",
    "        # TF-IDF Vectorization\n",
    "        tfidf_features = self.tfidf_vectorizer.fit_transform(emails)\n",
    "        \n",
    "        # Dimensionality Reduction\n",
    "        reduced_features = self.dimensionality_reducer.fit_transform(tfidf_features)\n",
    "        \n",
    "        # Standardization\n",
    "        processed_features = self.scaler.fit_transform(reduced_features)\n",
    "        \n",
    "        if labels is not None:\n",
    "            processed_labels = self.label_encoder.fit_transform(labels)\n",
    "            return processed_features, processed_labels\n",
    "        \n",
    "        return processed_features\n",
    "    \n",
    "    def train_with_cross_validation(self, X, y, n_splits=5):\n",
    "        \"\"\"\n",
    "        Advanced cross-validation training strategy\n",
    "        \n",
    "        Args:\n",
    "            X (array): Input features\n",
    "            y (array): Target labels\n",
    "            n_splits (int): Number of cross-validation splits\n",
    "        \n",
    "        Returns:\n",
    "            dict: Performance metrics for each model\n",
    "        \"\"\"\n",
    "        kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "        performance_metrics = {}\n",
    "        \n",
    "        for model_name, model in self.models.items():\n",
    "            cv_scores = cross_val_score(\n",
    "                model, \n",
    "                X, \n",
    "                y, \n",
    "                cv=kf, \n",
    "                scoring='neg_mean_squared_error'\n",
    "            )\n",
    "            performance_metrics[model_name] = {\n",
    "                'mean_cv_score': -cv_scores.mean(),\n",
    "                'std_cv_score': cv_scores.std()\n",
    "            }\n",
    "        \n",
    "        return performance_metrics\n",
    "    \n",
    "    def ablation_study(self, X, y):\n",
    "        \"\"\"\n",
    "        Comprehensive ablation study to understand model components\n",
    "        \n",
    "        Args:\n",
    "            X (array): Input features\n",
    "            y (array): Target labels\n",
    "        \n",
    "        Returns:\n",
    "            dict: Performance variations across different configurations\n",
    "        \"\"\"\n",
    "        ablation_results = {}\n",
    "        \n",
    "        # Configuration variations\n",
    "        configurations = [\n",
    "            {'feature_dim': 50},\n",
    "            {'feature_dim': 100},\n",
    "            {'feature_dim': 150},\n",
    "            {'feature_dim': 200},\n",
    "            {'regularization_strength': 0.01},\n",
    "            {'regularization_strength': 0.1},\n",
    "            {'regularization_strength': 1.0},\n",
    "            {'regularization_strength': 10.0},\n",
    "            {'tfidf_max_features': 3000},\n",
    "            {'tfidf_max_features': 7000}\n",
    "        ]\n",
    "        \n",
    "        # Original config backup\n",
    "        original_config = self.config.copy()\n",
    "        \n",
    "        for config in configurations:\n",
    "            # Update configuration\n",
    "            self.config.update(config)\n",
    "            \n",
    "            # Adjust the TfidfVectorizer if needed\n",
    "            if 'tfidf_max_features' in config:\n",
    "                self.tfidf_vectorizer = TfidfVectorizer(\n",
    "                    max_features=config['tfidf_max_features'],\n",
    "                    stop_words='english'\n",
    "                )\n",
    "            else:\n",
    "                self.tfidf_vectorizer = TfidfVectorizer(\n",
    "                    max_features=self.config.get('tfidf_max_features', 5000),\n",
    "                    stop_words='english'\n",
    "                )\n",
    "            \n",
    "            # Re-initialize model with new configuration\n",
    "            self.__init__(self.config)\n",
    "            processed_features, processed_labels = self.preprocess_data(X, y)\n",
    "            \n",
    "            # Train and evaluate\n",
    "            cv_results = self.train_with_cross_validation(\n",
    "                processed_features, \n",
    "                processed_labels\n",
    "            )\n",
    "            \n",
    "            ablation_results[str(config)] = cv_results\n",
    "        \n",
    "        # Restore the original configuration\n",
    "        self.config = original_config\n",
    "        self.__init__(self.config)\n",
    "        \n",
    "        return ablation_results\n",
    "    \n",
    "    def extreme_error_analysis(self, X, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Analyze extreme error cases in predictions\n",
    "        \n",
    "        Args:\n",
    "            X (array): Input features\n",
    "            y_true (array): True labels\n",
    "            y_pred (array): Predicted labels\n",
    "        \n",
    "        Returns:\n",
    "            dict: Extreme error insights\n",
    "        \"\"\"\n",
    "        errors = np.abs(y_true - y_pred)\n",
    "        error_threshold = np.percentile(errors, 95)\n",
    "        \n",
    "        extreme_error_indices = np.where(errors >= error_threshold)[0]\n",
    "        \n",
    "        return {\n",
    "            'extreme_error_indices': extreme_error_indices,\n",
    "            'max_error': errors.max(),\n",
    "            'min_error': errors.min(),\n",
    "            'mean_error': errors.mean(),\n",
    "            'median_error': np.median(errors)\n",
    "        }\n",
    "    \n",
    "    def bias_variance_decomposition(self, X, y):\n",
    "        \"\"\"\n",
    "        Perform bias-variance decomposition analysis\n",
    "        \n",
    "        Args:\n",
    "            X (array): Input features\n",
    "            y (array): Target labels\n",
    "        \n",
    "        Returns:\n",
    "            dict: Bias-variance decomposition metrics\n",
    "        \"\"\"\n",
    "        # Split data into training and validation sets\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "        \n",
    "        bias_variance_results = {}\n",
    "        \n",
    "        for model_name, model in self.models.items():\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Training performance\n",
    "            train_predictions = model.predict(X_train)\n",
    "            train_error = mean_squared_error(y_train, train_predictions)\n",
    "            \n",
    "            # Validation performance\n",
    "            val_predictions = model.predict(X_val)\n",
    "            val_error = mean_squared_error(y_val, val_predictions)\n",
    "            \n",
    "            bias_variance_results[model_name] = {\n",
    "                'train_error': train_error,\n",
    "                'validation_error': val_error,\n",
    "                'difference': abs(train_error - val_error)\n",
    "            }\n",
    "        \n",
    "        return bias_variance_results\n",
    "    \n",
    "    def visualize_results(self, results, output_path='results_visualization.png'):\n",
    "        \"\"\"\n",
    "        Create visualization for model performance and insights\n",
    "        \n",
    "        Args:\n",
    "            results (dict): Performance and analysis results\n",
    "            output_path (str): Path to save visualization\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.title('Model Performance Visualization')\n",
    "        \n",
    "        # Placeholder for actual visualization logic\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()\n",
    "        \n",
    "def main():\n",
    "    # email tects\n",
    "    email_summarization_tool = EmailSummarizationModel()\n",
    "    \n",
    "    # email texts\n",
    "    emails = [\n",
    "        \"\"\"Subject: Project Kickoff Meeting\n",
    "\n",
    "Hi Team,\n",
    "\n",
    "I hope this message finds you well. I’d like to schedule a project kickoff meeting for the new client initiative next Monday at 9 AM in Conference Room A. Please come prepared with your initial thoughts and any questions you might have.\n",
    "\n",
    "Looking forward to collaborating with all of you.\n",
    "\n",
    "Best regards,\n",
    "Jessica\"\"\",\n",
    "        \n",
    "        \"\"\"Subject: Request for Budget Approval\n",
    "\n",
    "Dear Finance Team,\n",
    "\n",
    "Attached is the budget proposal for the upcoming marketing campaign. Could you please review and approve it by the end of this week? Let me know if you need any additional information.\n",
    "\n",
    "Thank you,\n",
    "Mark\"\"\",\n",
    "        \n",
    "        \"\"\"Subject: Monthly Sales Report\n",
    "\n",
    "Hello All,\n",
    "\n",
    "Please find attached the sales report for June. We've seen a 15% increase in revenue compared to last month, largely driven by the new product launch. Let’s discuss the strategies that worked well in our next meeting.\n",
    "\n",
    "Best,\n",
    "Emily\"\"\",\n",
    "        \n",
    "        \"\"\"Subject: IT Maintenance Downtime\n",
    "\n",
    "Dear Employees,\n",
    "\n",
    "Please be advised that our IT department will perform scheduled maintenance on the servers this Saturday from 10 PM to 4 AM. During this time, access to email and internal systems will be unavailable. We apologize for any inconvenience this may cause.\n",
    "\n",
    "Thank you for your understanding,\n",
    "IT Support Team\"\"\",\n",
    "        \n",
    "        \"\"\"Subject: Invitation to Annual Company Retreat\n",
    "\n",
    "Hi Everyone,\n",
    "\n",
    "We are excited to announce our Annual Company Retreat will take place from August 5th to August 7th at Lakeview Resort. It’s a great opportunity to relax, network, and engage in team-building activities. Please RSVP by July 15th.\n",
    "\n",
    "Looking forward to seeing you there!\n",
    "\n",
    "Cheers,\n",
    "Amanda\"\"\",\n",
    "        \n",
    "        \"\"\"Subject: Feedback on Presentation\n",
    "\n",
    "Hi Daniel,\n",
    "\n",
    "Great job on the presentation yesterday! The data insights were particularly compelling. I have a few suggestions for the next session to make it even more impactful. Let’s schedule a brief meeting to discuss them.\n",
    "\n",
    "Best,\n",
    "Sophie\"\"\",\n",
    "        \n",
    "        \"\"\"Subject: New Hire Orientation Schedule\n",
    "\n",
    "Dear Team,\n",
    "\n",
    "We are pleased to welcome our new team members starting next Monday. Attached is the orientation schedule for their first week. Please ensure that all necessary preparations are made to facilitate a smooth onboarding process.\n",
    "\n",
    "Thank you,\n",
    "HR Department\"\"\",\n",
    "        \n",
    "        \"\"\"Subject: Client Meeting Follow-Up\n",
    "\n",
    "Hello Michael,\n",
    "\n",
    "Thank you for meeting with us yesterday regarding the partnership opportunities. As discussed, I’ve attached the proposal outlining our collaboration plan. Please review and let me know your thoughts by Friday.\n",
    "\n",
    "Best regards,\n",
    "Linda\"\"\",\n",
    "        \n",
    "        \"\"\"Subject: Office Renovation Updates\n",
    "\n",
    "Hi All,\n",
    "\n",
    "I wanted to update you on the ongoing office renovations. The main conference room will be closed for the next two weeks, but alternative spaces have been arranged. Please refer to the attached map for the new setup.\n",
    "\n",
    "Apologies for any inconvenience and thank you for your patience.\n",
    "\n",
    "Regards,\n",
    "Facilities Management\"\"\",\n",
    "        \n",
    "        \"\"\"Subject: Training Workshop on Data Analytics\n",
    "\n",
    "Dear Colleagues,\n",
    "\n",
    "We are organizing a training workshop on advanced data analytics on September 10th from 10 AM to 4 PM. This workshop will cover the latest tools and techniques in data analysis. Seats are limited, so please register by August 25th.\n",
    "\n",
    "Best,\n",
    "Training Coordinator\"\"\",\n",
    "        \n",
    "        \"\"\"Subject: Performance Bonus Announcement\n",
    "\n",
    "Hello Team,\n",
    "\n",
    "I’m thrilled to announce that due to our outstanding performance this quarter, the company has decided to award performance bonuses to all eligible employees. Details will be shared during the town hall meeting next Wednesday.\n",
    "\n",
    "Congratulations to everyone for your hard work!\n",
    "\n",
    "Best wishes,\n",
    "CEO\"\"\",\n",
    "        \n",
    "        \"\"\"Subject: Supply Chain Meeting Rescheduled\n",
    "\n",
    "Hi Team,\n",
    "\n",
    "Please note that the supply chain strategy meeting originally scheduled for Thursday has been moved to Friday at 2 PM in Conference Room B. Let me know if this new time poses any conflicts.\n",
    "\n",
    "Thanks,\n",
    "Operations Manager\"\"\",\n",
    "        \n",
    "        \"\"\"Subject: Policy Change: Remote Work Guidelines\n",
    "\n",
    "Dear Staff,\n",
    "\n",
    "Effective July 1st, we are updating our remote work policy to provide more flexibility. Attached is the revised document outlining the new guidelines and procedures. Please review it and reach out with any questions.\n",
    "\n",
    "Best regards,\n",
    "HR Team\"\"\",\n",
    "        \n",
    "        \"\"\"Subject: Security Alert: Phishing Attempt\n",
    "\n",
    "Hi Everyone,\n",
    "\n",
    "Be aware of a recent phishing attempt targeting our company email accounts. Do not click on any suspicious links or provide personal information. If you receive a dubious email, please report it to the IT department immediately.\n",
    "\n",
    "Stay safe,\n",
    "Cybersecurity Team\"\"\",\n",
    "        \n",
    "        \"\"\"Subject: Invitation to Speak at Tech Conference\n",
    "\n",
    "Dear Dr. Thompson,\n",
    "\n",
    "We are honored to invite you as a keynote speaker at the upcoming International Tech Conference on October 12th. Your expertise in artificial intelligence would be a valuable addition to our event. Please let us know your availability.\n",
    "\n",
    "Sincerely,\n",
    "Event Coordinator\"\"\"\n",
    "    ]\n",
    "    \n",
    "    # Corresponding summary labels\n",
    "    labels = [\n",
    "        \"Schedule project kickoff meeting next Monday at 9 AM.\",\n",
    "        \"Requesting budget approval for the marketing campaign by weeks end.\",\n",
    "        \"June sales report shows a 15% revenue increase.\",\n",
    "        \"Scheduled IT maintenance this Saturday from 10 PM to 4 AM.\",\n",
    "        \"Invitation to Annual Company Retreat from August 5th to 7th.\",\n",
    "        \"Positive feedback on presentation with suggestions for improvement.\",\n",
    "        \"Orientation schedule for new hires starting next Monday.\",\n",
    "        \"Follow-up on client meeting with attached collaboration proposal.\",\n",
    "        \"Update on office renovations and alternative conference room arrangements.\",\n",
    "        \"Invitation to data analytics training workshop on September 10th.\",\n",
    "        \"Announcement of performance bonuses due to outstanding quarterly results.\",\n",
    "        \"Rescheduled supply chain strategy meeting to Friday at 2 PM.\",\n",
    "        \"Updated remote work policy effective July 1st.\",\n",
    "        \"Security alert about a phishing attempt targeting company emails.\",\n",
    "        \"Invitation to Dr. Thompson to speak at International Tech Conference.\"\n",
    "    ]\n",
    "    \n",
    "    # Preprocessing\n",
    "    X, y = email_summarization_tool.preprocess_data(emails, labels)\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_results = email_summarization_tool.train_with_cross_validation(X, y)\n",
    "    print(\"Cross-Validation Results:\")\n",
    "    print(cv_results)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # Ablation study\n",
    "    ablation_results = email_summarization_tool.ablation_study(emails, labels)\n",
    "    print(\"Ablation Study Results:\")\n",
    "    for config, result in ablation_results.items():\n",
    "        print(f\"Config: {config}, Results: {result}\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # Bias-variance analysis\n",
    "    bias_variance_results = email_summarization_tool.bias_variance_decomposition(X, y)\n",
    "    print(\"Bias-Variance Decomposition Results:\")\n",
    "    print(bias_variance_results)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # Visualize results\n",
    "    email_summarization_tool.visualize_results(cv_results)\n",
    "    print(\"Results visualization saved to 'results_visualization.png'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary of the Results:**\n",
    "\n",
    "1. **Cross-Validation Performance:**\n",
    "   - **Random Forest:** Achieved a mean cross-validation MSE of approximately 36.13 with a standard deviation of about 22.38. The relatively high variance suggests that its performance is somewhat inconsistent across folds.\n",
    "   - **Gradient Boosting:** Had a mean MSE of roughly 60.52 with a standard deviation of about 18.54. Its error is notably higher than the other models, indicating weaker generalization.\n",
    "   - **Ridge Regression:** Showed the best performance among the three, with a mean MSE around 26.70 and a standard deviation of about 17.69. This model consistently outperformed the other two on the validation sets.\n",
    "\n",
    "2. **Ablation Study Results:**\n",
    "   - The ablation study examined the impact of altering feature dimensionality, regularization strength, and the number of TF-IDF features.\n",
    "   - **Effect on Random Forest and Gradient Boosting:** Their performance remained relatively stable across all tested configurations. Neither model showed significant improvement or degradation in mean MSE, suggesting they are not highly sensitive to the tested hyperparameter changes within the given range.\n",
    "   - **Effect on Ridge Regression:** Changes to regularization strength and TF-IDF features slightly influenced ridge regression results. For instance, increasing regularization strength to 10.0 or altering TF-IDF max features yielded a marginal improvement (mean MSE around 26.49), though differences were subtle. Overall, Ridge Regression remained the most robust and best-performing model across configurations.\n",
    "\n",
    "3. **Bias-Variance Decomposition:**\n",
    "   - **Random Forest:** Exhibited a low training error (~4.51) but a much higher validation error (~19.97), indicating some degree of overfitting. While it generalizes better than Gradient Boosting, it still struggles to match its training performance.\n",
    "   - **Gradient Boosting:** Nearly perfect on training (effectively zero error), but its validation error (~39.90) is very high. This extreme discrepancy highlights severe overfitting, as the model fails to generalize beyond its training data.\n",
    "   - **Ridge Regression:** Demonstrated a balanced behavior with a low training error (~0.08) and a moderate validation error (~9.73). The smaller gap between training and validation errors suggests a better bias-variance trade-off, making it the most stable and generalizable model of the three.\n",
    "\n",
    "**In essence, Ridge Regression consistently outperforms Random Forest and Gradient Boosting, is more robust to configuration changes, and maintains a good balance between bias and variance. Random Forest and Gradient Boosting, while competitive on training sets, suffer more from overfitting issues and do not adapt as well to modifications in feature dimensions or regularization settings.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
